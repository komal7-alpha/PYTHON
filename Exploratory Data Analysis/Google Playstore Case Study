Google Playstore Case Study
In this module you’ll be learning data visualisation with the help of a case study. This will enable you to understand how visualisation aids you in solving business problems.

Problem Statement

The team at Google Play Store wants to develop a feature that would enable them to boost visibility for the most promising apps. Now, this analysis would require a preliminary understanding of the features that define a well-performing app. You can ask questions like:

Does a higher size or price necessarily mean that an app would perform better than the other apps?
Or does a higher number of installs give a clear picture of which app would have a better rating than others?
Session 1 - Introduction to Data Visualisation
#import the libraries
import pandas as pd
import numpy as np
#read the dataset and check the first five rows
inp0 = pd.read_csv("googleplaystore_v2.csv")
inp0.head()

#Check the shape of the dataframe
inp0.shape
(10841, 13)
Data Handling and Cleaning
The first few steps involve making sure that there are no missing values or incorrect data types before we proceed to the analysis stage. These aforementioned problems are handled as follows:

For Missing Values: Some common techniques to treat this issue are

Dropping the rows containing the missing values
Imputing the missing values
Keep the missing values if they don't affect the analysis
Incorrect Data Types:

Clean certain values
Clean and convert an entire column
#Check the datatypes of all the columns of the dataframe
inp0.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10841 entries, 0 to 10840
Data columns (total 13 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   App             10841 non-null  object 
 1   Category        10841 non-null  object 
 2   Rating          9367 non-null   float64
 3   Reviews         10841 non-null  object 
 4   Size            10841 non-null  float64
 5   Installs        10841 non-null  object 
 6   Type            10840 non-null  object 
 7   Price           10841 non-null  object 
 8   Content Rating  10840 non-null  object 
 9   Genres          10841 non-null  object 
 10  Last Updated    10841 non-null  object 
 11  Current Ver     10833 non-null  object 
 12  Android Ver     10838 non-null  object 
dtypes: float64(2), object(11)
memory usage: 1.1+ MB
Missing Value Treatment
#Check the number of null values in the columns
inp0.isnull().sum()
App                  0
Category             0
Rating            1474
Reviews              0
Size                 0
Installs             0
Type                 1
Price                0
Content Rating       1
Genres               0
Last Updated         0
Current Ver          8
Android Ver          3
dtype: int64
Handling missing values for rating

Ratings is the target variable
drop the records
#Drop the rows having null values in the Rating field
inp1 = inp0[~inp0.Rating.isnull()]

#Check the shape of the dataframe
inp1.shape
(9367, 13)
# Check the number of nulls in the Rating field again to cross-verify
inp1.Rating.isnull().sum()
0
#Question
#Check the number of nulls in the dataframe again and find the total number of null values
inp1.isnull().sum()
App               0
Category          0
Rating            0
Reviews           0
Size              0
Installs          0
Type              0
Price             0
Content Rating    1
Genres            0
Last Updated      0
Current Ver       4
Android Ver       3
dtype: int64
#Inspect the nulls in the Android Version column
inp1[inp1['Android Ver'].isnull()]

inp1[inp1['Current Ver'].isnull()]

#Drop the row having shifted values
inp1[(inp1['Android Ver'].isnull() & (inp1.Category == "1.9"))]
#Check the nulls againin Android version column to cross-verify

inp1 = inp1[~(inp1['Android Ver'].isnull() & (inp1.Category == "1.9"))]
inp1[inp1['Android Ver'].isnull()]

Imputing Missing Values

For numerical variables use mean and median
For categorical variables use mode
#Check the most common value in the Android version column
inp1['Android Ver'].value_counts()
4.1 and up            2059
Varies with device    1319
4.0.3 and up          1240
4.0 and up            1131
4.4 and up             875
2.3 and up             582
5.0 and up             535
4.2 and up             338
2.3.3 and up           240
3.0 and up             211
2.2 and up             208
4.3 and up             207
2.1 and up             113
1.6 and up              87
6.0 and up              48
7.0 and up              41
3.2 and up              31
2.0 and up              27
5.1 and up              18
1.5 and up              16
3.1 and up               8
2.0.1 and up             7
4.4W and up              6
8.0 and up               5
7.1 and up               3
1.0 and up               2
5.0 - 8.0                2
4.0.3 - 7.1.1            2
4.1 - 7.1.1              1
7.0 - 7.1.1              1
5.0 - 6.0                1
Name: Android Ver, dtype: int64
inp1['Android Ver'].mode()[0]
'4.1 and up'
#inp1['Android Ver']['4.1 and up'].mean()
#Fill up the nulls in the Android Version column with the above value
inp1['Android Ver'] = inp1['Android Ver'].fillna(inp1['Android Ver'].mode()[0])
#Check the nulls in the Android version column again to cross-verify
inp1['Android Ver'].value_counts()
inp1['Android Ver'].isnull().sum()
0
#Check the nulls in the entire dataframe again
inp1.isnull().sum()
App               0
Category          0
Rating            0
Reviews           0
Size              0
Installs          0
Type              0
Price             0
Content Rating    0
Genres            0
Last Updated      0
Current Ver       4
Android Ver       0
dtype: int64
#Check the most common value in the Current version column
inp1['Current Ver'].mode()[0]
'Varies with device'
inp1['Current Ver'].value_counts()
Varies with device    1415
1.0                    458
1.1                    195
1.2                    126
1.3                    120
                      ... 
1.70                     1
24.8.1                   1
2.2.7600                 1
3.49.0202                1
1.7.10713 (281)          1
Name: Current Ver, Length: 2638, dtype: int64
#Replace the nulls in the Current version column with the above value
inp1['Current Ver'] = inp1['Current Ver'].fillna(inp1['Current Ver'].mode()[0])
# Question : Check the most common value in the Current version column again
inp1['Current Ver'].isnull().sum()
0
inp1['Current Ver'].value_counts()
Varies with device    1419
1.0                    458
1.1                    195
1.2                    126
1.3                    120
                      ... 
1.70                     1
24.8.1                   1
2.2.7600                 1
3.49.0202                1
1.7.10713 (281)          1
Name: Current Ver, Length: 2638, dtype: int64
Handling Incorrect Data Types
#Check the datatypes of all the columns 
inp1.dtypes
App                object
Category           object
Rating            float64
Reviews            object
Size              float64
Installs           object
Type               object
Price              object
Content Rating     object
Genres             object
Last Updated       object
Current Ver        object
Android Ver        object
dtype: object
#Question - Try calculating the average price of all apps having the Android version as "4.1 and up" 

#Analyse the Price column to check the issue
inp1.Price.value_counts()
0          8719
$2.99       114
$0.99       107
$4.99        70
$1.99        59
           ... 
$1.76         1
$2.00         1
$4.29         1
$1.20         1
$379.99       1
Name: Price, Length: 73, dtype: int64
#Write the function to make the changes

inp1.Price = inp1.Price.apply(lambda x : 0 if x=="0" else float(x[1:]))
#Verify the dtype of Price once again
inp1.dtypes
inp1.Price.value_counts()
0.00      8719
2.99       114
0.99       107
4.99        70
1.99        59
          ... 
299.99       1
1.59         1
1.61         1
3.90         1
2.90         1
Name: Price, Length: 73, dtype: int64
#Analyse the Reviews column
inp1.Reviews.value_counts()
2         83
3         78
5         74
4         74
1         67
          ..
454412     1
1992       1
6698       1
63186      1
2901       1
Name: Reviews, Length: 5992, dtype: int64
#Change the dtype of this column
inp1.Reviews = inp1.Reviews.astype("int32")
#Check the quantitative spread of this dataframe

inp1.Reviews.describe()
count    9.366000e+03
mean     5.140498e+05
std      3.144042e+06
min      1.000000e+00
25%      1.862500e+02
50%      5.930500e+03
75%      8.153275e+04
max      7.815831e+07
Name: Reviews, dtype: float64
#Analyse the Installs Column

## inp1.Reviews = inp1.Reviews.astype("int32")
inp1.Installs.value_counts()
1,000,000+        1577
10,000,000+       1252
100,000+          1150
10,000+           1010
5,000,000+         752
1,000+             713
500,000+           538
50,000+            467
5,000+             432
100,000,000+       409
100+               309
50,000,000+        289
500+               201
500,000,000+        72
10+                 69
1,000,000,000+      58
50+                 56
5+                   9
1+                   3
Name: Installs, dtype: int64
#Question Clean the Installs Column and find the approximate number of apps at the 50th percentile.


inp1['Installs'] = inp1['Installs'].map(lambda x: x.rstrip('+'))
inp1['Installs'] = inp1['Installs'].map(lambda x: ''.join(x.split(',')))
#def clean_Installs(val):
#    return val.replace(",","").replace("+","")
#inp1.Installs = inp1.Installs.apply(clean_Installs)
#inp1.Installs = inp1.Installs.apply(clean_Installs)
inp1.Installs.describe()
count        9366
unique         19
top       1000000
freq         1577
Name: Installs, dtype: object
inp1.Installs = inp1.Installs.astype("int64")
 
Sanity Checks
The data that we have needs to make sense and therefore you can perform certain sanity checks on them to ensure they are factually correct as well. Some sanity checks can be:

Rating is between 1 and 5 for all the apps.
Number of Reviews is less than or equal to the number of Installs.
Free Apps shouldn’t have a price greater than 0.
#Perform the sanity checks on the Reviews column
##inp1.dtypes
 ## inp1.Rating.describe()
inp1[(inp1.Reviews>inp1.Installs)].shape
(7, 13)
inp1[(inp1.Reviews>inp1.Installs)]

inp1 = inp1[(inp1.Reviews<=inp1.Installs)]
#pe rform the sanity checks on prices of free apps
inp2 = [(inp1.Type == "Free") & (inp1.Price>0)]
inp2
[0        False
 1        False
 2        False
 3        False
 4        False
          ...  
 10834    False
 10836    False
 10837    False
 10839    False
 10840    False
 Length: 9359, dtype: bool]
Outliers Analysis Using Boxplot
Now you need to start identifying and removing extreme values or outliers from our dataset. These values can tilt our analysis and often provide us with a biased perspective of the data available. This is where you’ll start utilising visualisation to achieve your tasks. And the best visualisation to use here would be the box plot. Boxplots are one of the best ways of analysing the spread of a numeric variable

Using a box plot you can identify the outliers as follows:

BoxPlots to Identify Outliers

Outliers in data can arise due to genuine reasons or because of dubious entries. In the latter case, you should go ahead and remove such entries immediately. Use a boxplot to observe, analyse and remove them.
In the former case, you should determine whether or not removing them would add value to your analysis procedure.
You can create a box plot directly from pandas dataframe or the matplotlib way as you learnt in the previous session. Check out their official documentation here:
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html
https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html
#import the plotting libraries
import matplotlib.pyplot as plt
%matplotlib inline
#Create a box plot for the price column
plt.boxplot(inp1.Price)
plt.show()
inp1.Price.describe()
Notebook Image
count    9359.000000
mean        0.961116
std        15.822478
min         0.000000
25%         0.000000
50%         0.000000
75%         0.000000
max       400.000000
Name: Price, dtype: float64
#Check the apps with price more than 200
inp1[inp1.Price>200]

#Clean the Price column
inp1 = inp1[inp1.Price<200]
#Create a box plot for paid apps
#inp1.Price.describe()
inp1[inp1.Price>0].Price.plot.box()
inp1.Price.describe()
#plt.show()
count    9344.000000
mean        0.334463
std         2.169925
min         0.000000
25%         0.000000
50%         0.000000
75%         0.000000
max        79.990000
Name: Price, dtype: float64
Notebook Image
#Check the apps with price more than 30
inp1[inp1.Price>30]

#Clean the Price column again
inp1 = inp1[inp1.Price<=30]
inp1.shape
(9338, 13)
Histograms
Histograms can also be used in conjuction with boxplots for data cleaning and data handling purposes. You can use it to check the spread of a numeric variable. Histograms generally work by bucketing the entire range of values that a particular variable takes to specific bins. After that, it uses vertical bars to denote the total number of records in a specific bin, which is also known as its frequency.

Histogram

You can adjust the number of bins to improve its granularity

Bins change

You'll be using plt.hist() to plot a histogram. Check out its official documentation:https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html

#Create a histogram of the Reviews
?plt.hist
plt.hist(inp1.Reviews)
(array([9.212e+03, 8.100e+01, 1.900e+01, 9.000e+00, 0.000e+00, 5.000e+00,
        0.000e+00, 3.000e+00, 7.000e+00, 2.000e+00]),
 array([1.00000000e+00, 7.81583150e+06, 1.56316620e+07, 2.34474925e+07,
        3.12633230e+07, 3.90791535e+07, 4.68949840e+07, 5.47108145e+07,
        6.25266450e+07, 7.03424755e+07, 7.81583060e+07]),
 <a list of 10 Patch objects>)
Notebook Image
#Create a boxplot of the Reviews column
plt.boxplot(inp1.Reviews)
{'whiskers': [<matplotlib.lines.Line2D at 0x1e75ac18788>,
  <matplotlib.lines.Line2D at 0x1e75ac18288>],
 'caps': [<matplotlib.lines.Line2D at 0x1e75ac0f208>,
  <matplotlib.lines.Line2D at 0x1e75ac14588>],
 'boxes': [<matplotlib.lines.Line2D at 0x1e75ac10ac8>],
 'medians': [<matplotlib.lines.Line2D at 0x1e7596ffac8>],
 'fliers': [<matplotlib.lines.Line2D at 0x1e75ac37648>],
 'means': []}
Notebook Image
#Check records with 1 million reviews
inp1[inp1.Reviews >= 1000000]

#Drop the above records

inp1 = inp1[inp1.Reviews <= 1000000]
inp1.shape
(8634, 13)
#Question - Create a histogram again and check the peaks

plt.hist(inp1.Reviews)
(array([7168.,  521.,  314.,  169.,  127.,  114.,   69.,   49.,   55.,
          48.]),
 array([1.000000e+00, 9.950110e+04, 1.990012e+05, 2.985013e+05,
        3.980014e+05, 4.975015e+05, 5.970016e+05, 6.965017e+05,
        7.960018e+05, 8.955019e+05, 9.950020e+05]),
 <a list of 10 Patch objects>)
Notebook Image
#Question - Create a box plot for the Installs column and report back the IQR

plt.boxplot(inp1.Installs)
inp1.Installs.describe()
count    8.634000e+03
mean     4.288536e+06
std      2.864650e+07
min      5.000000e+00
25%      1.000000e+04
50%      1.000000e+05
75%      1.000000e+06
max      1.000000e+09
Name: Installs, dtype: float64
Notebook Image
#Question - CLean the Installs by removing all the apps having more than or equal to 100 million 

inp1 = inp1[inp1.Installs <= 100000000]
inp1.shape
(8624, 13)
#Plot a histogram for Size as well.
plt.boxplot(inp1.Size)
plt.show()
plt.hist(inp1.Reviews)
Notebook Image
(array([7168.,  521.,  313.,  169.,  126.,  114.,   69.,   49.,   48.,
          47.]),
 array([1.000000e+00, 9.950110e+04, 1.990012e+05, 2.985013e+05,
        3.980014e+05, 4.975015e+05, 5.970016e+05, 6.965017e+05,
        7.960018e+05, 8.955019e+05, 9.950020e+05]),
 <a list of 10 Patch objects>)
Notebook Image
#Question - Create a boxplot for the Size column and report back the median value
inp1.Size.describe()
count      8624.000000
mean      21634.926354
std       20668.248638
min           8.500000
25%        6000.000000
50%       18000.000000
75%       26000.000000
max      100000.000000
Name: Size, dtype: float64
Session 2 - Data Visualisation with Seaborn
Seaborn is Python library to create statistical graphs easily. It is built on top of matplotlib and closely integrated with pandas.

Functionalities of Seaborn :

Dataset oriented API
Analysing univariate and bivariate distributions
Automatic estimation and plotting of linear regression models
Convenient views for complex datasets
Concise control over style
Colour palettes
#import the necessary libraries
import warnings
import seaborn as sns
warnings.filterwarnings("ignore")
Distribution Plots
A distribution plot is pretty similar to the histogram functionality in matplotlib. Instead of a frequency plot, it plots an approximate probability density for that rating bucket. And the curve (or the KDE) that gets drawn over the distribution is the approximate probability density curve.

The following is an example of a distribution plot. Notice that now instead of frequency on the left axis, it has the density for each bin or bucket.

Distplot

You'll be using sns.distplot for plotting a distribution plot. Check out its official documentation: https://seaborn.pydata.org/generated/seaborn.distplot.html

#Create a distribution plot for rating
##sns.distplot(inp1.Rating)
##sns.distplot(inp1.Rating,rug = False)
sns.distplot(inp1.Rating,kde = False)
plt.show()
Notebook Image
#Change the number of bins

sns.distplot(inp1.Rating, bins=15,vertical=True)
<matplotlib.axes._subplots.AxesSubplot at 0x1e75cf73c88>
Notebook Image
#Change the colour of bins to green
sns.distplot(inp1.Rating, bins=15,color="g")
<matplotlib.axes._subplots.AxesSubplot at 0x1e75d018148>
Notebook Image
#Apply matplotlib functionalities

sns.distplot(inp1.Rating, bins=15,color="g")
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
Styling Options
One of the biggest advantages of using Seaborn is that you can retain its aesthetic properties and also the Matplotlib functionalities to perform additional customisations. Before we continue with our case study analysis, let’s study some styling options that are available in Seaborn.

Check out the official documentation:https://seaborn.pydata.org/generated/seaborn.set_style.html
#Check all the styling options
?sns.set_style
#Change the number of bins to 20
sns.set_style("dark")
sns.distplot(inp1.Rating, bins=15,color="g")
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
sns.set_style("white")
sns.distplot(inp1.Rating, bins=15,color="g")
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
sns.set_style("darkgrid")
sns.distplot(inp1.Rating, bins=15,color="g")
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
plt.style.available
['bmh',
 'classic',
 'dark_background',
 'fast',
 'fivethirtyeight',
 'ggplot',
 'grayscale',
 'seaborn-bright',
 'seaborn-colorblind',
 'seaborn-dark-palette',
 'seaborn-dark',
 'seaborn-darkgrid',
 'seaborn-deep',
 'seaborn-muted',
 'seaborn-notebook',
 'seaborn-paper',
 'seaborn-pastel',
 'seaborn-poster',
 'seaborn-talk',
 'seaborn-ticks',
 'seaborn-white',
 'seaborn-whitegrid',
 'seaborn',
 'Solarize_Light2',
 'tableau-colorblind10',
 '_classic_test']
plt.style.use("dark_background")
sns.distplot(inp1.Rating, bins=15)
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
plt.style.use("default")
%matplotlib inline
sns.distplot(inp1.Rating, bins=15)
plt.title("distribution of apps ratings",fontsize = 12)
plt.show()
Notebook Image
Pie-Chart and Bar Chart
For analysing how a numeric variable changes across several categories of a categorical variable you utilise either a pie chart or a box plot

For example, if you want to visualise the responses of a marketing campaign, you can use the following views:

PieChart

barChart

You'll be using the pandas method of plotting both a pie chart and a bar chart. Check out their official documentations:
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.pie.html
#Analyse the Content Rating column
inp1['Content Rating'].value_counts()
Everyone           6938
Teen                928
Mature 17+          417
Everyone 10+        337
Adults only 18+       3
Unrated               1
Name: Content Rating, dtype: int64
#Remove the rows with values which are less represented 
inp1 = inp1[~inp1['Content Rating'].isin(["Adults only 18+","Unrated"])]
inp1['Content Rating'].value_counts()
Everyone        6938
Teen             928
Mature 17+       417
Everyone 10+     337
Name: Content Rating, dtype: int64
#Reset the index
inp1.reset_index(inplace = True,drop=True)
inp1.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 8620 entries, 0 to 8619
Data columns (total 13 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   App             8620 non-null   object 
 1   Category        8620 non-null   object 
 2   Rating          8620 non-null   float64
 3   Reviews         8620 non-null   int32  
 4   Size            8620 non-null   float64
 5   Installs        8620 non-null   int64  
 6   Type            8620 non-null   object 
 7   Price           8620 non-null   float64
 8   Content Rating  8620 non-null   object 
 9   Genres          8620 non-null   object 
 10  Last Updated    8620 non-null   object 
 11  Current Ver     8620 non-null   object 
 12  Android Ver     8620 non-null   object 
dtypes: float64(3), int32(1), int64(1), object(8)
memory usage: 841.9+ KB
#Check the apps belonging to different categories of Content Rating 
inp1['Content Rating'].value_counts().plot.pie()
<matplotlib.axes._subplots.AxesSubplot at 0x1e75d2af4c8>
Notebook Image
#Plot a pie chart

#Plot a bar chart
inp1['Content Rating'].value_counts().plot.bar()
<matplotlib.axes._subplots.AxesSubplot at 0x1e75d298248>
Notebook Image
#Question - Plot a bar plot for checking the 4th highest Android version type
inp1['Android Ver'].value_counts().plot.bar()
<matplotlib.axes._subplots.AxesSubplot at 0x1e75d1ddf48>
Notebook Image
Scatter Plots
Scatterplots are perhaps one of the most commonly used as well one of the most powerful visualisations you can use in the field of machine learning. They are pretty crucial in revealing relationships between the data points and you can generally deduce some sort of trends in the data with the help of a scatter plot.

Scatterplot

They're pretty useful in regression problems to check whether a linear trend exists in the data or not. For example, in the image below, creating a linear model in the first case makes far more sense since a clear straight line trend is visible.
Scatterplot-Reg

Also, they help in observing naturally occuring clusters. In the following image, the marks of students in Maths and Biology has been plotted.You can clearly group the students to 4 clusters now. Cluster 1 are students who score very well in Biology but very poorly in Maths, Cluster 2 are students who score equally well in both the subjects and so on.
Scatter-Clusters

Note: You'll be studying about both Regression and Clustering in greater detail in the machine learning modules

You'll be using sns.jointplot() for creating a scatter plot. Check out its documentation: https://seaborn.pydata.org/generated/seaborn.jointplot.html

###Size vs Rating

##Plot a scatter-plot in the matplotlib way between Size and Rating
plt.scatter(inp1.Size,inp1.Rating)
plt.show()
Notebook Image
### Plot the same thing now using a joint plot
sns.set_style("white")
sns.scatterplot(inp1.Size,inp1.Rating)
plt.show()
Notebook Image
## Plot a jointplot for Price and Rating
import scipy.stats as stats

#Change the code to the following
sns.jointplot(inp1.Size, inp1.Rating, stat_func = stats.pearsonr )
sns.jointplot(inp1.Size, inp1.Rating, kind = 'kde',color = 'g')
<seaborn.axisgrid.JointGrid at 0x1e75d08c2c8>
Notebook Image
Notebook Image
Reg Plots

These are an extension to the jointplots, where a regression line is added to the view
##Plot a reg plot for Price and Rating and observe the trend
sns.jointplot(inp1.Price,inp1.Rating)
plt.show()
Notebook Image
sns.distributions._has_statsmodels = False
sns.jointplot(inp1.Price,inp1.Rating,kind="reg")
plt.show()
Notebook Image
## Question - Plot a reg plot for Price and Rating again for only the paid apps.
Pair Plots

When you have several numeric variables, making multiple scatter plots becomes rather tedious. Therefore, a pair plot visualisation is preferred where all the scatter plots are in a single view in the form of a matrix
For the non-diagonal views, it plots a scatter plot between 2 numeric variables
For the diagonal views, it plots a histogram
Pair Plots help in identifying the trends between a target variable and the predictor variables pretty quickly. For example, say you want to predict how your company’s profits are affected by three different factors. In order to choose which you created a pair plot containing profits and the three different factors as the variables. Here are the scatterplots of profits vs the three variables that you obtained from the pair plot.

Pairplots

It is clearly visible that the left-most factor is the most prominently related to the profits, given how linearly scattered the points are and how randomly scattered the rest two factors are.

You'll be using sns.pairplot() for this visualisation. Check out its official documentation:https://seaborn.pydata.org/generated/seaborn.pairplot.html

?sns.pairplot()
Object `sns.pairplot()` not found.
## Create a pair plot for Reviews, Size, Price and Rating
sns.pairplot(inp1[['Reviews','Size','Price','Rating']])
plt.show()
Notebook Image
Bar Charts Revisited

Here, you'll be using bar charts once again, this time using the sns.barplot() function. Check out its official documentation:https://seaborn.pydata.org/generated/seaborn.barplot.html
You can modify the estimator parameter to change the aggregation value of your barplot
##Plot a bar plot of Content Rating vs Average Rating 
inp1.groupby(['Content Rating'])['Rating'].mean().plot.bar()
<matplotlib.axes._subplots.AxesSubplot at 0x1e75ee84848>
Notebook Image
##Plot the bar plot again with Median Rating
inp1.groupby(['Content Rating'])['Rating'].median().plot.bar()
<matplotlib.axes._subplots.AxesSubplot at 0x1e760635f08>
Notebook Image

sns.barplot(data = inp1, x = "Content Rating", y = "Rating")
plt.show()
Notebook Image
##Plot the above bar plot using the estimator parameter
sns.barplot(data = inp1, x = "Content Rating", y = "Rating", estimator = np.median)
plt.show()
Notebook Image
##Plot the bar plot with only the 5th percentile of Ratings
sns.barplot(data = inp1, x = "Content Rating", y = "Rating", estimator=lambda x: np.quantile(x,0.05))
plt.show()
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-1-367c6bb5e70f> in <module>()
      1 ##Plot the bar plot with only the 5th percentile of Ratings
----> 2 sns.barplot(data = inp1, x = "Content Rating", y = "Rating", estimator=lambda x: np.quantile(x,0.05))
      3 plt.show()

NameError: name 'sns' is not defined
##Question - Plot the bar plot with the minimum Rating
sns.barplot(data=inp1, x="Content Rating", y="Rating", estimator = np.min)
plt.show()
Notebook Image
Box Plots Revisited

Apart from outlier analysis, box plots are great at comparing the spread and analysing a numerical variable across several categories
Here you'll be using sns.boxplot() function to plot the visualisation. Check out its documentation: https://seaborn.pydata.org/generated/seaborn.boxplot.html
##Plot a box plot of Rating vs Content Rating
plt.figure(figsize=[9,7])
sns.boxplot(inp1["Content Rating"], inp1.Rating)
plt.show()
Notebook Image
##Question - Plot a box plot for the Rating column only
sns.boxplot(inp1.Rating)
plt.show()
Notebook Image
##Question - Plot a box plot of Ratings across the 4 most popular Genres

##inp1 = inp1[~inp1['Content Rating'].isin(["Adults only 18+","Unrated"])]
##inp1['Genres'].value_counts()

inp2 = inp1[inp1['Genres'].isin(["Tools","Entertainment","Education","Medical"])]
inp2['Genres'].value_counts()

Tools            694
Entertainment    508
Education        464
Medical          344
Name: Genres, dtype: int64
##Question - Plot a box plot of Ratings across the 4 most popular Genres
plt.figure(figsize=[9,7])
sns.boxplot(inp1["Rating"], inp2.Genres)
plt.show()
Notebook Image
Heat Maps
Heat mapsutilise the concept of using colours and colour intensities to visualise a range of values. You must have seen heat maps in cricket or football broadcasts on television to denote the players’ areas of strength and weakness.

HeatMap

In python, you can create a heat map whenever you have a rectangular grid or table of numbers analysing any two features
heatmap2

You'll be using sns.heatmap() to plot the visualisation. Checkout its official documentation :https://seaborn.pydata.org/generated/seaborn.heatmap.html
##Ratings vs Size vs Content Rating
## ?pd.qcut
##Prepare buckets for the Size column using pd.qcut

inp1["Size bucket"] = pd.qcut(inp1.Size,[0,0.2,0.4,0.6,0.8,1],["VL","L","M","H","VH"])
inp1.head()

##Create a pivot table for Size_buckets and Content Rating with values set to Rating
## ?pd.pivot_table
pd.pivot_table(data = inp1,index = "Content Rating",columns = "Size bucket",values = "Rating")

##Change the aggregation to median
pd.pivot_table(data = inp1,index = "Content Rating",columns = "Size bucket",values = "Rating",aggfunc= np.median)

##Change the aggregation to 20th percentile
pd.pivot_table(data = inp1,index = "Content Rating",columns = "Size bucket",values = "Rating",aggfunc= lambda x: np.quantile(x,0.2))

##Store the pivot table in a separate variable
##Change the aggregation to 20th percentile
res = pd.pivot_table(data = inp1,index = "Content Rating",columns = "Size bucket",values = "Rating",aggfunc= lambda x: np.quantile(x,0.2))
##Plot a heat map
sns.heatmap(res)
plt.show()
Notebook Image
##Apply customisations
sns.heatmap(res,cmap = "Greens",annot = True)
plt.show()
Notebook Image
##Question - Replace Content Rating with Review_buckets in the above heat map
##Keep the aggregation at minimum value for Rating
Session 3: Additional Visualisations
Line Plots
A line plot tries to observe trends using time dependent data.
For this part, you'll be using pd.to_datetime() function. Check out its documentation:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html
## Extract the month from the Last Updated Date
##inp1.dtypes
inp1['Last Updated'].head()
inp1['Updated month'] = pd.to_datetime(inp1['Last Updated']).dt.month
## Find the average Rating across all the months
inp1.groupby(['Updated month'])['Rating'].mean()
Updated month
1     4.143842
2     4.090385
3     4.107963
4     4.148326
5     4.153375
6     4.172590
7     4.222968
8     4.271086
9     4.041406
10    4.012739
11    4.102685
12    4.065350
Name: Rating, dtype: float64
## Plot a line graph
plt.figure(figsize = [10,5])
inp1.groupby(['Updated month'])['Rating'].mean().plot()
plt.show()
Notebook Image
Stacked Bar Charts
A stacked bar chart breaks down each bar of the bar chart on the basis of a different category
For example, for the Campaign Response bar chart you saw earlier, the stacked bar chart is also showing the Gender bifurcation as well
Stacked

## Create a pivot table for Content Rating and updated Month with the values set to Installs
pd.pivot_table(data = inp1 , values = "Installs", index = "Updated month",columns = "Content Rating",aggfunc = sum)

##Store the table in a separate variable
monthly = pd.pivot_table(data = inp1 , values = "Installs", index = "Updated month",columns = "Content Rating",aggfunc = sum) 
##Plot the stacked bar chart.
plt.figure(figsize = [10,6])
monthly.plot(kind = "bar",stacked = True)
<matplotlib.axes._subplots.AxesSubplot at 0x1e761e7af88>
<Figure size 720x432 with 0 Axes>
Notebook Image
##Plot the stacked bar chart again wrt to the proportions.
monthly_perc = monthly[["Everyone","Everyone 10+","Mature 17+","Teen"]].apply(lambda x : x/x.sum(),axis = 1)
monthly_perc.plot(kind = "bar",stacked="True",figsize = [10,6])
<matplotlib.axes._subplots.AxesSubplot at 0x1e75ebc83c8>
Notebook Image
Plotly
Plotly is a Python library used for creating interactive visual charts. You can take a look at how you can use it to create aesthetic looking plots with a lot of user-friendly functionalities like hover, zoom, etc.

Check out this link for installation and documentation:https://plot.ly/python/getting-started/

#Install plotly
import plotly.express as px
#Take the table you want to plot in a separate variable
res = inp1.groupby(["Updated month"])[["Rating"]].mean()
res.reset_index(inplace= True)
res

#Import the plotly libraries
#Prepare the plot
fig = px.line(res,x = "Updated month",y= "Rating",title="Monthly average rating")
fig.show()

 
